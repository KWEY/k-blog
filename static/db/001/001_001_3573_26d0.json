{
	"title": "Media Source Extension",
	"id": "001_001_3573_26d0",
	"time": "2019/1/13 下午4:34:32",
	"context": "<h3 id=\"articleHeader1\">1. 介绍</h3><p>这一节是非规范性的（non-normative）。<br>这个特性允许JavaScript去动态地为&lt;audio&gt;和&lt;video&gt;创建媒体流。它定义了一个MediaSource对象来给HTMLMediaElement提供媒体数据的源。MediaSource对象拥有一个或多个SourceBuffer对象。浏览器应用通过添加数据片段（data segments）给SourceBuffer对象，然后根据系统性能和其他因素来适应不同质量的后续data。SourceBuffer对象里的数据是被组建成需要被编码和播放的音频、视频和文字信息的轨道缓冲（track buffer）格式的。被用于扩展的二进制流格式结构如下图所示：<br><img src=\"https://w3c.github.io/media-source/pipeline_model.svg\" style=\"max-width:100%;\"><br></p><h4>1.1 目标</h4><ul><li>允许js去创建media stream，独立于普通的拉流播放的方式。</li><li>定义了一种加快自适应流，广告插入，时戳转换，视频编辑的分割和缓存模式。</li><li>最小化js中的媒体解析需要</li><li>尽可能的呃管理浏览器的播放缓存</li><li>提供二进制流格式操作需要</li><li>不需要支持特定的媒体格式和编解码器（codec）</li></ul><p>这个说明定义了</p><ul><li>浏览器和web app处理媒体数据的规范行为</li><li>其他定义媒体格式的</li></ul><h4>1.2 一些名词定义</h4><p><strong>Active Track Buffers&nbsp;</strong><br>一个提供开启中的音频track，选中的视频track，和正在显示或隐藏的字幕track的编码过的帧集合的track buffer。这些tracks都和activeSourceBuffers列表中的SourceBuffer对象有关。</p><p><strong>Append Window&nbsp;</strong><br>添加buffer时用于筛选coded frames的一个pts的range。append window表示一个连续的有单一开始和结束时间的时间区间。只有pts在这个时间区间内的编码帧才允许被添加到SourceBuffer中，其余的都会被筛选出去。append window的开始和结束时间是受appendWindowStart和appendWindowEnd两个属性分别控制。</p><p><strong>Coded Frame&nbsp;</strong><br>一个有presentation timestamp（pts）, decode timestamp（dts）和coded frame duration的媒体数据单元。</p><p><strong>Coded Frame Duration&nbsp;</strong><br>一个coded frame的时长，对视频和文字而言，duration就是指一个视频帧或者文字需要被展示的时间长度，对于音频而言，duration就是指这一帧中包括的采样的和。比如：一个包含441个采样样本的采样率是@44100Hz的音频帧的时长就是10ms。</p><p><strong>Coded Frame Group&nbsp;</strong><br>一组响铃的，dts单调递增没有gap的coded frames集合。如果被coded frame processing algorithm算法检测到的不连续片段就会触发abort方法从一个新的coded frame group开始重新播放。</p><p><strong>Decode Timestamp&nbsp;</strong><br>The decode timestamp（就是通常说的dts）表示最晚的这一帧和任何独立帧需要被解码的时间（假设可以被立刻解码和渲染，应该等于这个presentation order里最先被渲染的帧的pts）。如果这一帧不能在渲染顺序中被解码出来或者没有dts，那么dts就等于pts。</p><p><strong>Initialization Segment&nbsp;</strong><br>一系列的包括了需要解码media segment序列的初始化信息的二进制数据。包括了codec初始化信息，多路segment的Track ID的映射和时间戳偏移等。</p><p><strong>Media Segment&nbsp;</strong><br>一序列的包括了封装信息和时间戳信息的媒体数据二进制数据。Media Segment总是和最新添加的initialization segment相关。</p><p><strong>MediaSource object URL&nbsp;</strong><br>MediaSource object URL是一个唯一的通过createObjectURL()方法生成的Blob URI。用于绑定一个MediaSource对西那个到一个HTMLMediaElement元素上。</p><p><strong>Parent Media Source&nbsp;</strong><br>一个SourceBuffer对象的Parent Media Source是创建它的MediaSource对象。</p><p><strong>Presentation Start Time&nbsp;</strong><br>Presentation Start Time</p><p><strong>Presentation Interval&nbsp;</strong><br>一个coded frame的Presentation Interval是一个从pts到pts+coded frame's duration时间间隔。比如有一帧的pts是10s，coded frame duration是100ms，那么the presentation interval就是[10-10.1)。注意：起始时间是闭区间，结束时间是开区间。</p><p><strong>Presentation Order&nbsp;</strong><br>coded frames 渲染的顺序。The presentation order通过把coded frames 根据pts单调递增的排列起来获得。</p><p><strong>Presentation Timestamp&nbsp;</strong><br>视频帧显示的具体时间，表示了这一帧应该什么时候被播放器渲染。</p><p><strong>Random Access Point&nbsp;</strong><br>一个media segment可以不依赖之前数据解码和连续播放的位置。对于视频来说就是I-frames的位置，对音频来说大多数帧都可以作为random access point。因为视频轨道的random access point分布更稀疏，所以这些位置通常被当作复路流（multiplexed stream，我理解就是音视频等混合起来的流）的random access point。</p><p><strong>SourceBuffer byte stream format specification&nbsp;</strong><br>byte stream format specification特性描述了SourceBuffer实例允许的二进制流格式。是根据传入addSourceBuffer()方法的type。</p><p><strong>SourceBuffer configuration&nbsp;</strong><br>一个MediaSource实例下面的一个或多个SourceBuffer对象里的tracks集合。一个MediaSource对象必须支持以下至少一个设置：</p><ul><li>一个拥有音频和/或视频的SourceBuffer</li><li>两个SourceBuffer，其中一个单独处理音频轨道，一个单独处理视频轨道</li></ul><p><strong>Track Description&nbsp;</strong><br>一个二进制流数据结构，提供了单个track需要的TrackID，codec设置和其他metadata。一个initialization segment的每个track description都需要一个唯一的Track ID，如果不唯一的话，浏览器必须执行一个append error algorithm算法。</p><p><strong>Track ID&nbsp;</strong><br>用于识别二进制流数据属于那个track的标识。每个track description中的Track ID标识了一个 media segment属于的track</p><p><br></p><p><br></p><p><br></p><p><br></p>"
}